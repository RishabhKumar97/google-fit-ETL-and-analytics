{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45766803-d949-47e3-9754-4086f4f0e0dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DoubleType, IntegerType, DateType, LongType\n",
    "import pprint as pp\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe1d1eda-17ea-4e13-8130-5145adb0c5b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "create schema if not exists google_fit.silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "550a494e-2090-40b6-9408-2d8a0ead4511",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "silver ingestion base config"
    }
   },
   "outputs": [],
   "source": [
    "base_config_dict = {\n",
    "    \"activities\": {\n",
    "        \"bronze_table_name\": \"google_fit.bronze.activities\",\n",
    "        \"silver_table_name\": \"google_fit.silver.activities\",\n",
    "    },\n",
    "    \"all_sessions\": {\n",
    "        \"bronze_table_name\": \"google_fit.bronze.all_sessions\",\n",
    "        \"silver_table_name\": \"google_fit.silver.all_sessions\",\n",
    "    },\n",
    "    \"daily_activity_metrics\": {\n",
    "        \"bronze_table_name\": \"google_fit.bronze.daily_activity_metrics\",\n",
    "        \"silver_table_name\": \"google_fit.silver.daily_activity_metrics\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "098f0d0a-7c04-4629-a3f2-9473eb9136bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def build_silver_ingestion_config_dict():\n",
    "    \"\"\"\n",
    "    builds and returns the silver ingestion dict based on the basic config dict with the corresponding max ingestion timestamps of the bronze tables\n",
    "    \"\"\"\n",
    "    \n",
    "    # test_dict = {\"google_fit.bronze.activities\": \"2025-09-12 11:03:56.009982\", \"google_fit.bronze.all_sessions\": \"2025-09-12 11:03:59.785936\", \"google_fit.bronze.daily_activity_metrics\": \"2025-09-12 11:02:53.288683\"}\n",
    "    bronze_max_ingestion_timestamps_dict = json.loads(dbutils.jobs.taskValues.get(taskKey= \"bronze_ingestion\", key= \"bronze_max_ingestion_timestamps_dict\"))\n",
    "\n",
    "    silver_ingestion_config_dict = {k: v for k, v in base_config_dict.items()}\n",
    "\n",
    "    for table_name, timestamp in bronze_max_ingestion_timestamps_dict.items():\n",
    "        for feed, map_tables in silver_ingestion_config_dict.items():\n",
    "            if table_name == map_tables['bronze_table_name']:\n",
    "                map_tables['max_bronze_ingestion_timestamp'] = timestamp\n",
    "\n",
    "    return silver_ingestion_config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68e1f025-8563-4a3b-81e5-884fb7c1d638",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "silver_ingestion_config_dict = build_silver_ingestion_config_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb12fb1b-1b5d-42d3-966d-b33ebc45b4dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pp.pprint(silver_ingestion_config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3d75deb-0326-4470-80f1-2a4883378515",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Util functions"
    }
   },
   "outputs": [],
   "source": [
    "def null_check(df):\n",
    "    null_col_names = list()\n",
    "    for col in df.columns:\n",
    "        if df.filter(F.col(col).isNull()).count() > 0:\n",
    "            null_col_names.append(col)\n",
    "        else:\n",
    "            continue\n",
    "    return null_col_names\n",
    "\n",
    "def common_cleanup(df):\n",
    "    current_cols = df.columns\n",
    "    new_cols = [re.sub(r\"_{2,}\", \"_\", col.lower().replace(\"exploded\", \"\").strip().strip('_')) for col in current_cols]\n",
    "\n",
    "    df = df.toDF(*new_cols)\n",
    "    df = (\n",
    "        df.withColumn('entity', F.initcap(F.col('entity')))\n",
    "                     .select('entity', *[col for col in df.columns if col != 'entity'])\n",
    "    )\n",
    "    for col_info in df.schema:\n",
    "        if isinstance(col_info.dataType, DoubleType):\n",
    "            df = df.withColumn(col_info.name, F.round(col_info.name, 5))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e69acb19-d831-4348-88fb-f3d222b7db81",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Functions"
    }
   },
   "outputs": [],
   "source": [
    "def activities_silver_ingestion(silver_ingestion_config_dict):\n",
    "    bronze_table = silver_ingestion_config_dict['activities']['bronze_table_name']\n",
    "    silver_table = silver_ingestion_config_dict['activities']['silver_table_name']\n",
    "\n",
    "    activities_df = spark.table(bronze_table)\n",
    "    activities_df = common_cleanup(activities_df)\n",
    "    \n",
    "    # return activities_df\n",
    "    \n",
    "    if not spark.catalog.tableExists(silver_table):\n",
    "        print(f\"Starting overwrite operation for the table: {silver_table}\")\n",
    "        activities_df.write.saveAsTable(silver_table)\n",
    "        print(f\"Overwrite operation was successful on the table :{silver_table}\")\n",
    "    else:\n",
    "        max_bronze_ingestion_timestamp = silver_ingestion_config_dict['activities']['max_bronze_ingestion_timestamp']\n",
    "        activities_df = activities_df.filter(F.col('etl_timestamp') > F.lit(max_bronze_ingestion_timestamp))\n",
    "        print(f\"Starting append operation for the table: {silver_table}\")\n",
    "        activities_df.write.mode(\"append\").saveAsTable(silver_table)\n",
    "        print(f\"Append operation was successful on the table :{silver_table}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "585a9f0e-6163-444d-92a2-06c08a91d0ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def all_sessions_silver_ingestion(silver_ingestion_config_dict):\n",
    "    bronze_table = silver_ingestion_config_dict['all_sessions']['bronze_table_name']\n",
    "    silver_table = silver_ingestion_config_dict['all_sessions']['silver_table_name']\n",
    "\n",
    "    all_sessions_df = spark.table(bronze_table)\n",
    "    all_sessions_df = common_cleanup(all_sessions_df)\n",
    "\n",
    "    all_sessions_df = (\n",
    "        all_sessions_df.withColumn('duration_secs', F.regexp_replace(F.col('duration'), \"\\\\d(s)$\", 1))\n",
    "                        .drop('duration')\n",
    "                        .withColumn('endtime', F.to_utc_timestamp(F.col('endtime'), \"Z\"))\n",
    "                        .withColumn('starttime', F.to_utc_timestamp(F.col('starttime'), \"Z\"))\n",
    "                        .withColumn('segment_endtime', F.to_utc_timestamp(F.col('segment_endtime'), \"Z\"))\n",
    "                        .withColumn('segment_starttime', F.to_utc_timestamp(F.col('segment_starttime'), \"Z\"))\n",
    "                        .fillna({\"aggregate_floatvalue\": 0, \"aggregate_intvalue\": 0})\n",
    "                        .withColumn('aggregate_metricname', F.regexp_replace(F.regexp_replace(F.col('aggregate_metricname'), \"^com\\\\.google\\\\.\", \"\"), \"\\\\.\", \"_\"))\n",
    "                        .withColumn('segment_fitnessactivity', F.initcap(F.col('segment_fitnessactivity')))\n",
    "    )\n",
    "    \n",
    "    # return all_sessions_df\n",
    "\n",
    "    if not spark.catalog.tableExists(silver_table):\n",
    "        print(f\"Starting overwrite operation for the table: {silver_table}\")\n",
    "        all_sessions_df.write.saveAsTable(silver_table)\n",
    "        print(f\"Overwrite operation was successful on the table :{silver_table}\")\n",
    "    else:\n",
    "        max_bronze_ingestion_timestamp = silver_ingestion_config_dict['all_sessions']['max_bronze_ingestion_timestamp']\n",
    "        all_sessions_df = all_sessions_df.filter(F.col('etl_timestamp') > F.lit(max_bronze_ingestion_timestamp))\n",
    "        print(f\"Starting append operation for the table: {silver_table}\")\n",
    "        all_sessions_df.write.mode(\"append\").saveAsTable(silver_table)\n",
    "        print(f\"Append operation was successful on the table :{silver_table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d36afd23-5c0e-43a7-8412-40105871bb32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def daily_activity_metrics_silver_ingestion(silver_ingestion_config_dict):\n",
    "    bronze_table = silver_ingestion_config_dict['daily_activity_metrics']['bronze_table_name']\n",
    "    silver_table = silver_ingestion_config_dict['daily_activity_metrics']['silver_table_name']\n",
    "\n",
    "    daily_activity_metrics_df = spark.table(bronze_table)\n",
    "\n",
    "    for col in daily_activity_metrics_df.columns:\n",
    "        if(re.search(r'date', col.lower())):\n",
    "            daily_activity_metrics_df = daily_activity_metrics_df.withColumn(col, F.when(F.col(col).isNotNull(), F.col(col).cast(DateType())).otherwise(None))\n",
    "        elif re.search(r'count|minutes', col.lower()):\n",
    "            daily_activity_metrics_df = daily_activity_metrics_df.withColumn(col, F.when(F.col(col).isNotNull(), F.col(col).cast(IntegerType())).otherwise(None))\n",
    "        elif re.search(r'speed|distance|kcal|weight|points', col.lower()):\n",
    "            daily_activity_metrics_df = daily_activity_metrics_df.withColumn(col, F.when(F.col(col).isNotNull(), F.col(col).cast(DoubleType())).otherwise(None))\n",
    "        elif(re.search(r'duration', col.lower())):\n",
    "            daily_activity_metrics_df = daily_activity_metrics_df.withColumn(col, F.when(F.col(col).isNotNull(), F.col(col).cast(LongType())).otherwise(None))\n",
    "\n",
    "    daily_activity_metrics_df = daily_activity_metrics_df.fillna(0)\n",
    "    daily_activity_metrics_df = common_cleanup(daily_activity_metrics_df)\n",
    "    cur_cols = daily_activity_metrics_df.columns\n",
    "    daily_activity_metrics_df = daily_activity_metrics_df.toDF(*[col.replace(\"_m_s\", \"_ms\") for col in cur_cols])\n",
    "\n",
    "    # return daily_activity_metrics_df\n",
    "\n",
    "    if not spark.catalog.tableExists(silver_table):\n",
    "        print(f\"Starting overwrite operation for the table: {silver_table}\")\n",
    "        daily_activity_metrics_df.write.saveAsTable(silver_table)\n",
    "        print(f\"Overwrite operation was successful on the table :{silver_table}\")\n",
    "    else:\n",
    "        max_bronze_ingestion_timestamp = silver_ingestion_config_dict['daily_activity_metrics']['max_bronze_ingestion_timestamp']\n",
    "        daily_activity_metrics_df = daily_activity_metrics_df.filter(F.col('etl_timestamp') > F.lit(max_bronze_ingestion_timestamp))\n",
    "        print(f\"Starting append operation for the table: {silver_table}\")\n",
    "        daily_activity_metrics_df.write.mode(\"append\").saveAsTable(silver_table)\n",
    "        print(f\"Append operation was successful on the table :{silver_table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "004a17ae-9763-4880-96ec-451641c481a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def silver_ingestion(silver_ingestion_config_dict_dict):\n",
    "    futures = []\n",
    "    with ThreadPoolExecutor(len(silver_ingestion_config_dict_dict)) as e:\n",
    "        activities_silver_ingestion_future = e.submit(activities_silver_ingestion, silver_ingestion_config_dict_dict)\n",
    "        futures.append(activities_silver_ingestion_future)\n",
    "        all_sessions_silver_ingestion_future = e.submit(all_sessions_silver_ingestion, silver_ingestion_config_dict_dict)\n",
    "        futures.append(all_sessions_silver_ingestion_future)\n",
    "        daily_activity_metrics_silver_ingestion_future = e.submit(daily_activity_metrics_silver_ingestion, silver_ingestion_config_dict_dict)\n",
    "        futures.append(daily_activity_metrics_silver_ingestion_future)\n",
    "      \n",
    "    for f in as_completed(futures):\n",
    "        f.result()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c2883cc-3dc4-4cf1-b040-d230f43b1d40",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Main call"
    }
   },
   "outputs": [],
   "source": [
    "silver_ingestion(silver_ingestion_config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c3ef737-a992-47d4-9ba8-2e7f938059b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "799295b7-85ac-4ba5-b588-73351aa5703b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Exit notebook"
    }
   },
   "outputs": [],
   "source": [
    "dbutils.notebook.exit(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67907dcf-7ea7-44d1-9d83-30678538d814",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.table(silver_ingestion_config['activities']['silver_table_name']).count() == spark.table(silver_ingestion_config['activities']['bronze_table_name']).count()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5809602586140871,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_ingestion",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
